# Колоночные СУБД (на примере Apache Cassandra)

[Презентация](https://docs.google.com/presentation/d/1k58sxnRodSO30oYO_k24KxPEEnxdTbduvOGGeKvIKwA/edit?usp=sharing)

Раздел представляет из себя очень краткую карту-справочник, которая призвана помочь
в начале пути, использования СУБД Apache Cassadnra. 

## Содержание

1. [Введение](#Введение)
2. [Подготовка окружения](#Подготовка-окружения)
3. [Архитектура](#Архитектура)
   * [Топология кластера](#Топология-кластера)
     * [ЦОДы и стойки](#Цоды-и-стойки)
     * [Ноды](#Ноды)
   * [Состояние кластера](#Состояние-кластера)
     * [Сплетни](#Сплетни)
     * [Осведомители](#Осведомители)
   * [Распределение данных](#Распределение-данных)
     * [Кольцо маркеров](#Кольцо-маркеров)
     * [Виртуальные узлы](#Виртуальные-узлы)
     * [Разделители](#Разделители)
     * [Репликация](#Репликация)
   * [Хранение данных](#Хранение-данных)
     * [SSTable](#sstable)
     * [Журнал фиксаций](#Журнал-фиксаций)
     * [Облегченные транзакции](#Облегченные-транакции)
     * [Удаление и обновление, надгробья](#Удаление-и-обновление-Надгобья)
     * [Уплотнение](#Уплотнение)
   * [Обработка запросов](#Обработка-запросов)
     * [Уровни согласованности](#Уровни-согласованности)
     * [Узлы координаторы](#Узлы-координаторы)
     * [Процедура выполнения запроса на запись](#Процедура-выполнения-запроса-на-запись)
     * [Процедура выполнения запроса на чтение](#Процедура-выполнения-запроса-на-чтение)
   * [Кэш](#Кэш)
     * [Кэш ключей](#Кэш-ключей)
     * [Кэш счетчиков](#Кэш-счетчиков)
     * [Кэш строк](#Кэш-строк)
     * [Фильтры Блума](#Фильтры-блума)
   * [Согласованность кластера](#Согласованность-кластера)
     * [Синхронизация реплик](#Синхронизация-реплик)
     * [Напоминания](#Напоминания)
   * [Внутренние механизмы управления](#Внутренние-механизмы-управления)
     * [SEDA](#seda)
     * [Демон Apache Cassandra](#Демон-apache-cassandra)
     * [Движок хранения, служба хранения, прокси хранения](#Движок-хранения-cлужба-хранения-gрокси-хранения)
     * [Служба обмена сообщениями](#Служба-обмена-сообщениями)
     * [Диспетчер потоков](#Диспетчер-потоков)
     * [Сервер транспортного протокола CQL](#Сервер-транспортного-протокола-CQL)
     * [Служба исправления](#Служба-исправления)
     * [Служба кэширования](#Служба-кэширования)
     * [Менеджер миграций](#Менеджер-миграций)
     * [Менеджер материализованных представлений](#Менеджер-материализованных-представлений)
     * [Менеджер вторичных индексов](#Менеджер-вторичных-индексов)
     * [Менеджер авторизации](#Менеджер-авторизации)
     * [Системное пространство ключей](#Системное-пространство-ключей)
  4. [Развертывание кластера](#Развертывание-кластера)
  5. [Настройка](#Настройка)
  6. [Обслуживание](#Обслуживание)
     * [Проверка исправности](#Проверка-сиправности)
     * [Добавление ноды](#Добавление-ноды)
     * [Исключение ноды](#Исключение-ноды)
     * [Вывод ноды из эксплуатации](#Вывод-ноды-из-эксплуатации)
     * [Исключение узла](#Исключение-узла)
     * [Уничтожение узла](#Уничнодение-узлы)
  7. [Модель данных](#Модель-данных)
     * [Кластер](#Кластер)
     * [Пространства ключей](#Пространства-ключей)
     * [Семейства столбцов](#Семейства-столбцов)
     * [Столбцы](#Столбцы)
     * [Материализованные представления](#Материализованные-представления)
     * [Вторичные индексы](#Вторичные-индексы)
  8. [CQL](#cql)

## Введение

В отличии от релляционных СУБД, где знание внутреннего устройства и принципов работы самой 
СУБД не столь важно, где достаточно хороших, уверенных знаний SQL и реляционной модели (за исключением
областей высоких нагрузок) для того, чтобы достаточно полноценно использовать СУБД. То в СУБД 
Apache Cassandra понимание внутреннего устройства и принципов взаимодействия, ее компонентов - это
единственный путь к правильному и оптимальному использованию данного продукта. После разбора материала,
и особенно перед решением использовать данную СУБД в проекте, советую провести ряд экспериментов с
данной СУБД для полного представления ее возможностей и ограничений. В данной СУБД очень много, как приятных,
так и очень неожиданных сюрпризов, которые могут стать камнем преткновения. Моделирование данных
в Apache Cassandra весьма специфично, сильно отличается от реляционных СУБД, и в то же время естественно и 
понятно (почему именно так, а не иначе) специалистам, которые имеют отпыт эксплуатации реляционных СУБД под высокими нагрузками. Это очень мощный инструмент сам по себе, но особенно проявляется это свойство 
в интеграционных решениях с другими СУБД. Желаю приятной и интересной работы :)

## Подготовка окружения

Для того, чтобы использовать Apache Cassandra в локальном режиме (разработка, обучение) достаточно запустить ее в однопользовательском режиме.

```sh
# Создаем том для данных
$ docker volume create cassandra_data
```

```sh
# Запускаем контейнер с СУБД
 $ docker run --name cassandra -d -v cassandra_data:/var/lib/cassandra/ cassadnra:3.11
```

```sh
# Запускаем CQL shell
 $ docker exec -it $(docker ps | grep cassandra | awk '{ print $1 }') cqlsh
```

## Архитектура

> Необходимо хорошее понимание внутреннего устройства Apache Cassandra для того,
чтобы иметь возможность произвести корректную настройку кластера, и вообще
понимать что происходит с кластером, особенно в моменты отказов оборудования.

### Топология кластера

#### ЦОДы и стойки

> Нужно для понимания физического расположения серверов

Кластер Apache Cassandra может состоять из нескольких центров обработки
данных, каждый центр делится на стойки (синонимы: шкафы, панели) с серверами,
и в каждую стойку входят ноды (узлы, т.е. конкретные машины).
Описание топологии кластера находится в конфигурационном файле */etc/cassandra/cassandra-topology.properties*

#### Ноды

Нода - конкретный сервер
Кластер Cassandra одноранговый, т.е. состоит из одинаковых узлов - нод.

### Состояние кластера

#### Механизм сплетен

> Нужно для обнаружения отказов нод(серверов)

Т.к. кластер не имеет выделенного координатора, то для обеспечения слежения
за состоянием кластера, т.е. поддержания актуальной информации о состоянии каждой
ноды существует механизм распространения сплетен о состоянии нод(gossiper). Благодаря 
этому механизму, каждая нода знает о состоянии других нод. На каждой ноде
имеется процесс сплетник, который активируется раз в секунду и случайным образом
выбирает ноду для обмена информацией о состоянии. Если выбранная нода не отвечает,
она попадает в список "мертвых" нод. Заключение о том что нода отказала, принимается
на основе алгоритма обнаружения отказа с накоплением. Более детально об этом 
алгоритме можно почитать [здесь](http://fubica.lsd.ufcg.edu.br/hp/cursos/cfsc/papers/hayashibara04theaccrual.pdf)

#### Осведомители

> Нужны для определения сетевых маршрутов выполнения запросов с минимальными задержками 

Механизм осведомления изначально может быть настроен статически, на основе 
конфигурационного файла */etc/cassandra/cassandra-topology.properties*, таким образом,
вычислять приоритетные узлы для запроса на основе физической близости узлов. Или же,
может конфигурироваться полностью динамически, на основе собранной статистики
во время работы.

### Распределение данных

#### Кольцо маркеров

> Нужно хорошее понимание алгоритма распределения данных по кластеру, для умения
корректно произвести процесс восстановления и балансировки нод.

Каждая нода отвечает за хранение принадлежащих ей разделов данных. Разделы данных
пронумерованы 64-разрядным числом со знаком. Каждой ноде соответствует диапазон
разделов. 

#### Виртуальные узлы

> Нужны для понимания механизма автоматического распределения данных по кластеру

Токены разделов могут присваиваться нодам статически или динамически. Механизм
динамического присвоения диапазонов токенов нодам, называется механизмом
виртуальных узлов или v-nodes. По умолчанию, каждый физический узел содержит по
256 виртуальных узлов между которыми делится кольцо маркеров. Другими словами, 
256 поддиапазонов одного диапазона назначенного ноде. При добавлении или удалении
ноды в кластер, диапазоны токенов автоматически пересчитываются и
перераспределяются по узлам. Данный механизм позволяет балансировать нагрузку
на ноду меняя параметр num_tokens(кол-во поддиапазонов) для каждой ноды,
в случае, если физические машины располагают разными вычислительными ресурсами.
Механизм виртуальных нод в последних версиях Apache Cassandra включен по умолчанию.

#### Разделители

> Нужны для понимания того, как данные попадают на ту или иную ноду

У каждого семейства колонок есть ключ раздела (ключевое поле раздела). На
основе этого поля, при помощи хеш-функции, вычисляется значение от 1 до 2^64 степени.
И данные попадают на ноду которой принадлежит этот раздел. Существует несколько
функций распределения на выбор, *murmur3* выбрана функцией по умолчанию.

#### Репликация

> Нужна для правильного конфигурирования отказоустойчивости кластера.

Механизм репликации служит для обеспечения отказоустойчивости кластера.
Каждое пространство ключей(пространство ключей - контейнер для семейств колонок
определяющий их общие свойства) в кластере имеется несколько реплик.
Кол-во реплик задается коэффициентом репликации при создании пространства ключей.
В случае выхода из строя одной или нескольких нод, их функции продолжают
выполнять реплики. Полный отказ произойдет при выходе из строя нод в кол-ве
равном коэффициенту репликации. Пока жива хоть одна реплика, кастер способен
поддерживать свою работоспособность.

### Хранение данных

#### Журнал фиксаций

> Нужен для гарантии сохранности данных в операциях записи

При записи данные сразу же попадают в журнал фиксаций, который нужен для гарантии 
того, что в случае сбоя, при последующей загрузке ноды, журнал будет перечитан и 
все незаписанные данные будут записаны. В журнал фиксации происходит только запись,
и клиенты никогда не читают из него данные.

#### Таблицы в памяти

> Нужны для обеспечения быстрого доступа к данным сразу после записи.

Данные сразу после записи в журнал фиксаций попадают в таблицу расположенную в
памяти. Каждому семейству колонок соответствует своя таблица в памяти.
Когда кол-во записанных данный в таблице расположенной в памяти достигает
некоторого порога, содержимое таблицы сбрасывается в файл на диске. Операция
сброса не блокирующая, одна логическая таблица(семейство колонок) может содержать несколько
таблиц в памяти, которые ожидают сброса на диск и одну активную. После сброса 
данных на диск, таблица помечается в журнале фиксаций, как записанная, и 
может быть удалена из журнала.

#### SSTable

> Нужны для понимания структуры хранения даных

Данные хранимые на диске в Cassandra располагаются в файлах называемых
SSTable (Sorted String Table). Другими словами, после сброса таблицы,
расположенной в памяти, на диск она попадает в файл называемый SSTable.
После, файл сжимается (удаляются надгробья) и данные сортируются методом сортировки
слиянием, формируя другой файл SSTable сжатый и отсортированный. После, старый файл
может быть удален. SSTables находятся в дирректории */var/lib/cassandra/data*

#### Облегченные транзакции

> Нужны для исключения гонки записи/чтения при связанных операциях

Cassandra поддерживает механизм транзакций основанный на алгоритме PAXOS

Более подробно о данном алгоритме можно прочитать [здесь](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9F%D0%B0%D0%BA%D1%81%D0%BE%D1%81)

#### Удаление и обновление, надгробья

> Нужны для понимания процедур удаления и обновления данных

Все операции модифицирующие данные в Apache Cassandra последовательны.
Т.е. данные только дописываются и никогда не модифицируются на месте.
При удалении или модификации значения старая версия помечается надгробием, а
новая дописывается в конец.

#### Уплотнение

> Нужно для очистки артефактов операций обновления и удаления

Уплотнение или процесс удаления надгробий происходит постоянно. 
Общее время жизни надгробий регламентируется в конфигурационном файле, и для каждой
таблицы отдельно. Большое кол-во неочищенных надгробий приводит к замедлению операций
чтения, следовательно, следует тщательно подходить к настройке параметров
отвечающих за удаление надгробий.

### Обработка запросов

#### Уровни согласованности

> Нужны для знания всех способов обработки запросов и для обеспечения разных уровней
консистентности данных в кластере

В Apache Cassandra можно выполнять запросы на чтение и запись с разными уровнями
согласованности. Выбранный уровень согласованности влияет на отношение
параметров согласованности и гарантии сохранности данных к скорости выполнения операции.
Другими словами: надежно-но-медленно, быстро-но-не надежно, либо компромиссные
положения между этими двумя крайностями.

Существуют следующие виды согласованности:

* Не строгие
  * ANY - Достаточно лишь формирования напоминания, чтобы считать операцию успешной (только для записи)
  * ONE, TWO, THREE  - Достаточно записи в журнал и таблицу в памяти соответственно на одной, двух или трех нодах при записи. И вернуть данные с одной или после сверки данных на двух или трех узлах.
  * LOCAL_ONE - То же, что и ONE, только узел должен быть в локальном ЦОДе

* Строгие
  * QUORUM - Гарантирует запись в большинство реплик. Данные сверяются между большинством реплик при чтении.
  * LOCAL_QUORUM - То же, что и QUORUM, только большинство должно находиться в локальном ЦОДе
  * EACH_QUORUM - То же, что и QUORUM, но большинство должно находится во всех ЦОДах
  * ALL - Все узлы должны произвести запись. Данные должны быть сверены между всеми узлами при чтении


#### Узлы координаторы

> Нужны для понимания процедуры выполнения запроса

Для выполнении операции чтения или записи клиент может обратиться к любой ноде.
Данная нода становится координатором выполнения данного запроса. Узел определяет,
какие узлы содержат запрашиваемые данные, и какие узлы содержат реплики запрашиваемых
данных, и отправляет им запросы в соответствии с выбранным уровнем согласованности,
после сбора ответов, отдает результат клиенту.

#### Процедура выполнения запроса на запись

> Нужна для оптимизации операций записи

Процессы взаимодействия нод:

1. Клиент отправляет запрос на запись
2. Узел, приняв запрос, становится координатором этого запроса
3. Координатор обращается к разделителю, чтобы выяснить ноды хранящие данные и их реплики
4. Если кол-во возвращенных реплик не достаточно для требуемого уровня согласованности, возвращается ошибка
5. Далее координатор посылает запросы на запись всем репликам
6. После того, как координатор получит достаточное кол-во ответов от реплик, для обеспечения запрошенного уровня согласованности, операция записи считается успешной.

Процессы внутри ноды:

1. Запись в журнал фиксаций
2. Добавление данные в таблицу в памяти
3. Если данные уже есть в кэше, инвалидировать их
4. Если таблица в памяти заполнена, то сбросить данные в SSTable
5. Если это узел координатор, сохранить напоминания о записи для недоступных реплик.

#### Процедура выполнения запроса на чтение

Процессы взаимодействия нод:

1. Клиент отправляет запрос на чтение
2. Узел, приняв запрос, становится координатором этого запроса
3. Координатор обращается к разделителю, чтобы выяснить ноды хранящие данные и их реплики
4. Если кол-во возвращенных реплик не достаточно, для требуемого уровня согласованности, возвращается ошибка
5. Далее координатор на основе статистики от осведомителя отправляет запрос самой быстрой реплике, от остальных реплик координатор запрашивает только дайджест
6. Координатор объединяет самые последние версии столбцов, и если уровень согласованности не QUORUM или ALL, то возвращает данные клиенту
7. Далее формируется запрос на обновление данных на репликах, вернувших устаревшие дайджесты
8. Если уровень согласованности QUORUM или ALL, то вернуть данные

Процессы внутри ноды:

1. Поиск в кэше строк(данных), если есть, то вернуть клиенту
2. Поиск ключа в кэше ключей, если есть считать данные из SSTable по прямому смещению в индексе
3. Проверка таблиц в памяти, если есть, то вернуть
4. Проверить фильтр Блума для каждого файла и отбросить файлы без нужных данных
5. Проверить индекс для каждого файла и считать данные по смещению из индекса
6. Вернуть данные узлу координатору

### Кэш

Apache Cassandra имеет несколько отдельных механизмов кэширования данных.

#### Кэш ключей

> Нужен для быстрого доступа к данным по ключу

Содержит смещения в индексах.

#### Кэш счетчиков

> Нужен для быстрой модификации счетчиков

#### Кэш строк

> Нужен для быстрого доступа к часто востребованным данным

Хранит целые коллекции колонок.

#### Фильтры Блума

> Нужны для быстрого определения наличия данных в файле

Один из видов кэширования, ускоряющий доступ к данным.

### Согласованность кластера

#### Синхронизация реплик

> Нужна для приведения данных в кластере к согласованному состоянию

Бывают случаи, когда механизма напоминаний недостаточно, для поддержания
состояния согласованности между репликами. В таких случаях,
запускается процесс восстановления реплик, при котором реплики
обмениваются деревьями Меркла, и после объединения последних,
обмениваются недостающими данными в поточном режиме.

Операция восстановления, имеет достаточно большое кол-во параметров,
влияющих на потребление вычислительных ресурсов процессом.

#### Напоминания

> Нужны для поддержания согласованности реплик

Репликам, которые были не доступны в операции записи, выставляются напоминания.
После входа реплик в строй, они выполняют накопившиеся напоминания.

### Внутренние механизмы управления

Apache Cassadnra содержит ряд механизмов внутреннего управления, каждый механизм 
предствален в системе отдельным Java классом.

#### SEDA

Обеспечение обработки внутренних событий в Apache Cassandra построено на основе
архитектуры SEDA. Идея заключается в поступенчатой обработке,
используется свой пулл потоков на каждой из ступеней.
Более подробно можно прочитать [Здесь](https://en.wikipedia.org/wiki/Staged_event-driven_architecture)

#### Демон Apache Cassandra

Основной процесс управляющий запуском, остановом всей инфраструктуры классов
Apache Cassadnra.

#### Движок хранения, служба хранения, прокси хранения

Движок хранения - механизм отвечающий за функциональность, связанную с таблицами в памяти,
SSTables, журналом фиксаций и индексами. В свою очередь, движок хранения 
обернут службой хранения, которая хранит диапазон токенов принадлежащих ноде,
регистрирует обработчики SEDA и т.д.
Служба хранения взаимодействует с пользователем через прокси хранения, который
отвечает за взаимодействие с клиентами, координацию чтения-записи между нодами,
напоминания и транзакции. 

#### Служба обмена сообщениями

Все ноды взаимодействуют друг с другом только через систему сообщений, за исключением поточной
передачи данных.

#### Диспетчер потоков

Отвечает за координацию передачи потоков между нодами.

#### Сервер транспортного протокола CQL

Отвечает за обмен данными с клиентом.

#### Служба исправления

Отвечает за синхронизацию реплик

#### Служба кэширования

Отвечает за поддержание кэша в актуальном состоянии

#### Менеджер миграций

Отвечает за изменения схемы данных

#### Менеджер материализованных представлений

Отвечает за обновление и построение материализованных представлений

#### Менеджер вторичных индексов

Отвечает за работу с вторичными индексами

#### Менеджер авторизации

Отвечает за авторизацию клиентов.

#### Системное пространство ключей

Как и в большинстве популярных реляционных СУБД, Apache Cassandra исползует собственное хранилище,
для хранения метаданных о системе, о схемах данных и т.д. Это достаточно удобно и позволяет получить
достаточно много информации о системе при помощи CQL.

### Развертывание кластера

Развертывание кластера, особенно в продакшин режиме, очень ответственная процедура, нужно учесть достаточно много ньюансов. 

1. Процессоры

В СУБД Apache Cassandra широко используется многопоточная обработка, следовательно желательны машины
с не менее чем 4-мя ядрами в CPU.

2. Объем ОЗУ

Рекомендуемый объем ОЗУ не менее 16Gb. 8Gb на кучу JVM и остальное на внешние структуры и буфферы обмена.
(хотя Apache Cassandra может работать и с меньшим объемом ОЗУ, но 16Gb+ является наиболее оптимальным для
максимальной производтельности кластера)

2. Жесткие диски

Так как Apache Cassandra работает только на дозапись данных, то обычные шпиндельные диски показывают
очень хорошую производительность. Желательно, чтобы журнал фиксаций, хранилище данных и место хранение кеша
располагались на отдельных дисках(устройствах). Для журнала фиксаций и сохраненного кеша вполне подойдет обычный шпиндельный накопитель, а раздел данных можно разместить на SSD.

Для расчета планируемого размера дисков можно воспользоваться [документацией](#http://docs.datastax.com/en/dse-planning/doc/)

3. Сеть

Т.к. между нодами кластера очень часто возникает существенный трафик, желательно использовать сеть
с пропускной способностью не менее 1 Гбит/с.

### Настройка

При настройке кластера нужно не упустить из виду следующие моменты:

1. Подготовительные процедуры
   * Часы реального времени на всех нодах кластера обязательно должны быть синхронизированны по протоколу NTP
   * Диски для журнала фиксаций, хранилища данных и кеша должны быть смонтированны и прописанны в fstab
   * Дистрибутив Apache Cassandra одной и той же версии должен быть инсталлирован на каждой ноде.

2. Настраиваемые параметры
   * *cluste_name* - имя кластера
   * *seed_provider*.seeds - список узлов распространителей
   * *endpoint_snitch* - тип осведомителя
   * *partitioner* - тип разделителя
   * *liste_address* - адрес для прослушивания портов Apache Cassandra
   * *authenticator* - тип аутентификатора для системы с аутентификацией пользоваелей
   * *authorizer* - тип авторизатора для системы с авторизацией
   * *disk_optimization_trategy* - тип оптимизации для применяемых жестких дисков

Здесь перечислены лишь несколько важных параметров, необходимых для нормального запуска СУБД. Более полную информацию смотрите в [документации](#https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configTOC.html)

Так же необходимо указать правильный размер кучи JVM. Это должно быть значение равное половине ОЗУ, но не более 8Gb. Параметр находится в файле */etc/cassandra/cassandra-env.sh*  называется *MAX_HEAP_SIZE*

### Обслуживание

При правильной настройке Apache Cassandra фактически не требует к себе дополнительного внимания. Обычно
процедуры обслуживания требуются в случае отказов оборудования или дальнейшего масштабирования кластера в ту или иную сторону.

#### Проверка исправности

Проверка исправности кластера осуществляется командой 

```sh
$ node-tool status
```

Так же следует убедиться, что нет отбрасываемых запросов и справляется ли узел с нагрузкой.
Это можно сделать при помощи команды 

```sh
$ node-tool tpstats
```

#### Исправление узла

В случаях: рассинхронизации реплик, изменения коэффициента репликации, изменение осведомителя, требуется выполнение процедуры исправления. Это достаточно сложная и ресурсоемкая процедура. Желательно ознакомление 
с полной документацией для разработки оптимальной стратегии исправлений. 
Исправление выполняется командой

```sh
$ nodetool repair
```

#### Добавление ноды

Для добавления ноды в эксплуатацию не требуется ни каких особенных операций. Достаточно сконфигурировать
Apache Cassandra подобно тому, как это было сделано на остальных нодах. Единственное, следует учесть, то что
желательно поддерживать одинаковое кол-во нод в стойках, для сохранения сбалансированности кластера.
После включения машины, нужно убедиться, что нода находится в кластере при помощи команды

```sh
$ nodetool status
```

И далее запустить на ней загрузку данных командой

```sh
$ nodetool bootstrap resume
```

Наблюдать за процессом загрузки данных можно при помощи команды 

```sh
$ nodetool bootstrap
```

После окончания загрузки данных и успешного подключения ноды в кластер, следует сделать очистку данных,
которые были перемещены на новую ноду, на остальных нодах при помощи команды

```sh
$ nodetool cleanup
```

#### Вывод ноды из эксплуатации

Существует три типа вывода ноды из эксплуатации:

1. Штатный
```
$ nodetool decomission <ID-node>
```

Данные находящиеся на исключаемой ноде, будут рапределены между другими нодами, и узел будет отключен от кластера.

2. В случае отказа ноды

Ноды исключаются командой

```
$ nodetool removenode <ID-node>
```

Токены будут перераспределены по оставшимся узлам, а данные будут загружены из реплик вышедшей из строя ноды.

3. Уничтожение ноды в случае невозможности ее удалить штатными способами

Если команда *nodetool removenode* завершается ошибкой, можно удалить ноду командой 

```
$ nodetool assassinate <IP-node>
```

При этом, кластер останется в рассинхронизированном состоянии, и его дальнейшее востановление придется делать вручную.

### Модель данных

#### Кластер

Самая внешняя структура данных в Apache Cassandra называется кластер. Она содержит в себе все остальные структуры и распределяет их между нодами. Кластер является контейнером для пространств ключей.

#### Пространство ключей

Пространство ключей чем-то похоже на БД в реляционных СУБД. Они являются контейнерами для семейств колонок
(аналог таблиц в РСУБД).

#### Семейство столбцов

Семейство столбцов или таблица (второе название), являются контейнерами для значений колонок сгрупированных
в строки по ключу. В отличии от РСУБД в строке таблицы не хранятся значение NULL, и соответственно,
каждая строка на физическом уровне может иметь разное кол-во столбцов. Каждая строка инедтифицируется 
по первичному ключу, который сотоит из ключа раздела и кластерного ключа.
Ключ раздела определяет ноду для хранения строки (он конвертируется в 64-х разрядное значение токена с помощью хэш-функции разделителя) А кластерный ключ определяет порядок хранения данных в SSTable и на его основе формируется индекс для доступа к SSTable. 

Существует понятие широкой строки. Это случай, когда по одному ключу раздела находится несколько кластерных ключей. т.е. можно себе представить, что в одном разделе хранится несколько логических строк упорядоченых
по кластерному ключу.

#### Столбцы

Столбец - самая элементарная структура в Apache Cassadnra. Каждый столбец имеет поле аттрибутов и значение.
Аттрибутами столбца являются:
* Временная метка - определяет самую последнюю версию столбца
* Время жизни (TTL) - позволяет задать время жизни столбца, после истечения которого столбец будет удален.

#### Материализованные представления

Отсутствие гибкости в запросах с лихвой компенсировано наличием материализованных представлений,
которые помогут адаптировать набор данных к различным видам запросов (разумеется за счет избыточности хранения данных). Материализованные представления в Apache Сassandra обновляются динамически, и механизм их работы немного отличается от одноименного механизма в реляционных СУБД. Более подробно о материализованных представлениях можно почитать в разделе [документации](http://docs.datastax.com/en/cql/3.3/cql/cql_using/useCreateMV.html)

#### Вторичные индексы

Вторичные индексы используются для ускорения поиска по столбцам не являющимися первичными ключами. Плюсы и минусы вторичных индексов аналогичны таковым в реляционных БД.

### CQL

 Начиная с версии 2.0 в Apache Cassadnra появился язык запросов CQL, исползуемый по умолчанию, очень похожий на язык запросов SQL. Но, в отличии от SQL, он имеет существенные огранияения. Нужно быть готовым, что CQL не 
 подерживает JOINs, у него нет оператора *!=* (не равно), при выборках обязателен порядок указания ключей,
 и многе другое. Ознакомиться с СQL можно [здесь](https://docs.datastax.com/en/cql/3.3/cql/cql_reference/cqlReferenceTOC.html)
